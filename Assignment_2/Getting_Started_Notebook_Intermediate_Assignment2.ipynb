{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Getting_Started_Notebook_Intermediate_Assignment2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dphi-official/Deep_Learning_Bootcamp/blob/master/Assignment_2/Getting_Started_Notebook_Intermediate_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01quEXe2_bkz",
        "colab_type": "text"
      },
      "source": [
        "**Please follow the below instructions to load the dataset in Notebook.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD3WuCgn_rTe",
        "colab_type": "text"
      },
      "source": [
        "## Download Data\n",
        "We are given google drive link in the ‘Data’ section of problem page which has all the required train images (to build the model) and test data images for which one need to predict the labels (animal specie) of these images and submit the predictions on the DPhi platform.\n",
        "\n",
        "\n",
        "\n",
        "We can use GoogleDriveDownloader from google_drive_downloader library in Python to download the shared files from the Google drive link: https://drive.google.com/file/d/176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D/view?usp=sharing\n",
        "\n",
        "The file id in the above link is: 176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2TWoO5-bIyL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c74d4ed7-0533-459f-9db3-3bd51502f974"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D',\n",
        "                                    dest_path='content/animals_data.zip',\n",
        "                                    unzip=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D into content/animals_data.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgxihnh0LCHQ",
        "colab_type": "text"
      },
      "source": [
        "**Now we are all set to start the data science work!!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJnmEJt9EY-2",
        "colab_type": "text"
      },
      "source": [
        "## Loading Libraries\n",
        "Let's import the required libraries. Not importing all the libraries in one go instead we will be importing whenever we require one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb2W2sgLBim4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv0LmgNbEwR0",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnUBZ_ZOEvOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = {\"elefante_train\": \"elefante\", \"farfalla_train\": \"farfalla\", \"mucca_train\": \"mucca\", \"pecora_train\": \"pecora\", \"scoiattolo_train\": \"scoiattolo\"}\n",
        "data=[]\n",
        "animals=[\"elefante\", \"farfalla\", \"mucca\",  \"pecora\", \"scoiattolo\"]\n",
        "img_size=100      # Here we are taking image size as 100, but it's on you. You can take 50 or 40 or 32 and so on\n",
        "def create_data():\n",
        "        for category,translate in categories.items():\n",
        "            path=\"/content/content/animal_dataset_intermediate/train/\"+category\n",
        "            target=animals.index(translate)     # converting the categorical values to numbers - 0, 1, 2, 3, 4 denoting the animals in animals list\n",
        "            \n",
        "            for img in os.listdir(path):         # os.listdir gets you all the list of name of files located in the given path\n",
        "                try:\n",
        "                    img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)    # converts the image to pixels and gray scales the images\n",
        "                    new_img_array=cv2.resize(img_array,(img_size,img_size))              # resizing the images\n",
        "                    data.append([new_img_array,target])                                  # appending the list of image pixels and respective target value (i.e. animal type) in data\n",
        "                except Exception as e:\n",
        "                    pass                                      # try and except is exception handling case in python, saves you from getting errors\n",
        "                \n",
        "            \n",
        "create_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtJqd-PNgRpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data   # data contains all the images pixel values and their respective labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgcCiao3ciQ3",
        "colab_type": "text"
      },
      "source": [
        "## Split the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftcG0gxacKV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can split data using train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKuPUvVVVpee",
        "colab_type": "text"
      },
      "source": [
        "## Building Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KycYYRpFVcoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC-89PXPWnKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXlgaWFccFzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5hxDG16dixs",
        "colab_type": "text"
      },
      "source": [
        "## Optimize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEz8zyzadl0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUd93mhpdmug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vivxhUK8dmfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSh2YMO9c80X",
        "colab_type": "text"
      },
      "source": [
        "# Loading the Test Data\n",
        "We can load the test data similar to train_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iseum_zjc53c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the csv file given 'Testing_set_animals.csv'\n",
        "test_image_ids = pd.read_csv(\"/content/content/animal_dataset_intermediate/Testing_set_animals.csv\")\n",
        "test_image_ids.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkc8_Ry_dUo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get image paths\n",
        "image_paths = ['/content/content/animal_dataset_intermediate/test/' + fname for fname in test_image_ids['filename']]\n",
        "image_paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x29cVsdeK3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confirm if number of images is same as number of labels given\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXmLVJ7peu2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataframe of image ids and filepaths\n",
        "test_data = pd.DataFrame({'filename': ****, 'filepath': ****})\n",
        "test_data.head()\n",
        "\n",
        "\"\"\"\n",
        "please put the required data at ****\n",
        "\"\"\"\n",
        "# this is completely optional to see if all the data images are in an order. You can skip this if you want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPf2E4dZfOk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load image pixels using cv2\n",
        "image_pixels = []\n",
        "for i in range(****):\n",
        "  img_array = cv2.imread(****)\n",
        "  image_pixels.append(****)\n",
        "\n",
        "\"\"\"\n",
        "Put required data at ****\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLINT8JQb9Yz",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtQFzeFogwI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCgiIiG9kG6S",
        "colab_type": "text"
      },
      "source": [
        "**Note: Follow the submission guidelines given in ‘[How To Submit](https://discuss.dphi.tech/t/how-to-submit-predictions/548)’ Section.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI9CATQwkVJd",
        "colab_type": "text"
      },
      "source": [
        "# **How to save prediciton results locally via jupyter notebook?**\n",
        "If you are working on Jupyter notebook, execute below block of codes. A file named ‘submission.csv’ will be created in your current working directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avhrRAeOkOOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.DataFrame({'filename': test_data['filename'], 'animal_type': prediction})  # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
        "res.to_csv(\"submission.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3g3ttCgke7i",
        "colab_type": "text"
      },
      "source": [
        "# **OR,**\n",
        "**If you are working on Google Colab then use the below set of code to save prediction results locally**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-tXRapAkpoe",
        "colab_type": "text"
      },
      "source": [
        "# **How to save prediction results locally via colab notebook?**\n",
        "If you are working on Google Colab Notebook, execute below block of codes. A file named ‘submission’ will be downloaded in your system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGmEaU75kmfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.DataFrame({'filename': test_data['filename'], 'animal_type': prediction})  # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
        "res.to_csv(\"submission.csv\") \n",
        "\n",
        "# To download the csv file locally\n",
        "from google.colab import files        \n",
        "files.download('submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}